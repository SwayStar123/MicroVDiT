{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import datasets\n",
    "from diffusers import AutoencoderKL\n",
    "import torch\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.config.HF_HUB_OFFLINE = 1 # Comment this out if you havent downloaded the dataset yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since tpremoli/CelebA-attrs couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at datasets\\CelebA-attrs\\train\\tpremoli___celeb_a-attrs\\default\\0.0.0\\ed9021d2871ceddbd3cf0fb642544bd7c60c5152 (last modified on Wed Sep 11 12:26:31 2024).\n",
      "Using the latest cached version of the dataset since tpremoli/CelebA-attrs couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at datasets\\CelebA-attrs\\validation\\tpremoli___celeb_a-attrs\\default\\0.0.0\\ed9021d2871ceddbd3cf0fb642544bd7c60c5152 (last modified on Mon Aug 26 18:16:43 2024).\n",
      "Using the latest cached version of the dataset since tpremoli/CelebA-attrs couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at datasets\\CelebA-attrs\\test\\tpremoli___celeb_a-attrs\\default\\0.0.0\\ed9021d2871ceddbd3cf0fb642544bd7c60c5152 (last modified on Mon Aug 26 18:18:41 2024).\n"
     ]
    }
   ],
   "source": [
    "train_ds = load_dataset(\"tpremoli/CelebA-attrs\", cache_dir=\"datasets/CelebA-attrs/train\", split=\"train\")\n",
    "validation_ds = load_dataset(\"tpremoli/CelebA-attrs\", cache_dir=\"datasets/CelebA-attrs/validation\", split=\"validation\")\n",
    "test_ds = load_dataset(\"tpremoli/CelebA-attrs\", cache_dir=\"datasets/CelebA-attrs/test\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((216, 176)),  # Resize to 176x216 (Height x Width)\n",
    "    transforms.ToTensor(),           # Convert to tensor\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Scale to [-1, 1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_sample(sample):\n",
    "    sample[\"image\"] = transform(sample[\"image\"])\n",
    "    return sample\n",
    "\n",
    "train_ds = train_ds.map(transform_sample)\n",
    "validation_ds = validation_ds.map(transform_sample)\n",
    "test_ds = test_ds.map(transform_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.with_format(type='torch', columns=['image'], output_all_columns=True)\n",
    "validation_ds = validation_ds.with_format(type='torch', columns=['image'], output_all_columns=True)\n",
    "test_ds = test_ds.with_format(type='torch', columns=['image'], output_all_columns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = AutoencoderKL.from_pretrained(\"madebyollin/sdxl-vae-fp16-fix\", cache_dir=\"models/vae\")\n",
    "vae = vae.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "762d3f62dcc14baa94f4adba70b5ba0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/162770 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\diffusers\\models\\attention_processor.py:1584: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  hidden_states = F.scaled_dot_product_attention(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4244e2658724d28a52dd6178f8ff154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19962 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dcd8ae5bf44495593603a4fe7b16506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19867 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transform2 = lambda x: vae.encode(x.to(device)).latent_dist.sample().cpu()\n",
    "\n",
    "def transform_sample2(sample):\n",
    "    sample[\"latents\"] = transform2(sample[\"image\"])\n",
    "    return sample\n",
    "\n",
    "train_ds = train_ds.map(transform_sample2, batched=True, batch_size=32, remove_columns=[\"image\"])\n",
    "validation_ds = validation_ds.map(transform_sample2, batched=True, batch_size=32, remove_columns=[\"image\"])\n",
    "test_ds = test_ds.map(transform_sample2, batched=True, batch_size=32, remove_columns=[\"image\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66bb3633f64a4da9b59eb4ed7f38561e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/153 shards):   0%|          | 0/162770 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1e5b8ee0f0f4ccfb2b913e50a18cad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/19 shards):   0%|          | 0/19962 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c7b87e33ec24ba8a5ebedcabab6fa61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/19 shards):   0%|          | 0/19867 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ds.save_to_disk(\"datasets/CelebA-attrs-latents/train\")\n",
    "validation_ds.save_to_disk(\"datasets/CelebA-attrs-latents/validation\")\n",
    "test_ds.save_to_disk(\"datasets/CelebA-attrs-latents/test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
